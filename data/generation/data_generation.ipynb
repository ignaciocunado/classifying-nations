{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from scipy.special import factorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneration(ABC):\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "def __init__(self, ran_var, ran_int, n_fix, sim, fix=None, lengths=None, y=None, N=None, t=None):\n",
    "    self.sim = sim\n",
    "    self.ran_var = ran_var\n",
    "    self.ran_int = ran_int\n",
    "    self.n_fix = n_fix\n",
    "    if self.sim:\n",
    "        self.subgroups_teor = np.array([2, 5, 3])  # number of subgroups\n",
    "        self.groups_teor = len(self.subgroups_teor)  # number of groups created\n",
    "        self.N = np.sum(self.subgroups_teor)\n",
    "        self.data = None\n",
    "        self.eta = None\n",
    "        self.t = None\n",
    "    else:\n",
    "        self.N = N\n",
    "        self.t = t\n",
    "\n",
    "    if self.ran_var:\n",
    "        self.z = 2  # we need z for accessing the fixed parameters of glm_mat\n",
    "    else:\n",
    "        self.z = 1\n",
    "\n",
    "    if self.N > 100:\n",
    "        self.nknots = 100\n",
    "    else:\n",
    "        self.nknots = self.N\n",
    "\n",
    "    self.weights = np.array([1 / self.nknots] * self.nknots)  \n",
    "    # creating a np.array of 1/nknots with length nknots\n",
    "\n",
    "    # from the methods\n",
    "    self.fix = fix\n",
    "    self.lengths = lengths\n",
    "    self.y = y\n",
    "    self.glm_mat = None\n",
    "    self.par = None\n",
    "    self.range_min, self.range_max, self.knots = None, None, None\n",
    "\n",
    "    def generate_curves(self):\n",
    "    rude_data = []  # list of eta (total value)\n",
    "    rude_t = []  # list of random effects\n",
    "    rude_fix = defaultdict(list)  # list of list of fixed effects\n",
    "\n",
    "    sd = 1\n",
    "    mu = 0\n",
    "    # lengths = np.random.randint(70, 100, size=3)\n",
    "    lengths = np.array([])\n",
    "    for i in range(self.groups_teor):\n",
    "        for j in range(self.subgroups_teor[i]):\n",
    "            length = np.random.randint(70, 100, size=1)[0]\n",
    "            lengths = np.append(lengths, length)\n",
    "            x = np.sort(np.random.normal(loc=mu, scale=sd, size=length))\n",
    "            f = np.array([np.random.normal(loc=mu, scale=sd, size=length) for k in range(self.n_fix)])\n",
    "            # x = np.sort(np.random.normal(loc=mu, scale=sd, size=lengths[i]))\n",
    "            # f = np.array([np.random.normal(loc=mu, scale=sd, size=lengths[i]) for k in range(self.n_fix)])\n",
    "\n",
    "            eta = self.int_values[i]\n",
    "            if self.ran_var:\n",
    "                eta += self.ran_var_values[i] * x\n",
    "                rude_t.append(x)\n",
    "\n",
    "            for k in range(self.n_fix):\n",
    "                eta += self.fix_var_values[k] * f[k]\n",
    "                rude_fix[k].append(f[k])\n",
    "\n",
    "            rude_data.append(eta)\n",
    "\n",
    "    return rude_data, rude_t, rude_fix, lengths.astype(int)  # np.repeat(lengths, self.subgroups_teor) #lengths\n",
    "\n",
    "    @abstractmethod\n",
    "    def compute_eta_and_y(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def compute_glm_mat(self):\n",
    "        pass\n",
    "\n",
    "    def compute_par(self):\n",
    "        par = np.median(self.glm_mat[:, self.z:], axis=0)\n",
    "        if not self.ran_int:\n",
    "            par_0 = np.median(self.glm_mat[:, 0])\n",
    "            par = np.insert(par, 0, par_0)  \n",
    "            # adding par_0 before position 0 of par\n",
    "        return par\n",
    "\n",
    "    @staticmethod\n",
    "    def tukey_fences(col, val):\n",
    "        if val == 0.25:\n",
    "            return np.quantile(col, val) - 1.5 * (np.quantile(col, 0.75) - np.quantile(col, 0.25))\n",
    "        elif val == 0.75:\n",
    "            return np.quantile(col, val) + 1.5 * (np.quantile(col, 0.75) - np.quantile(col, 0.25))\n",
    "\n",
    "    def compute_ranges_knots(self):\n",
    "        n_col = self.glm_mat.shape[1]\n",
    "        range_min = np.array([self.tukey_fences(self.glm_mat[:, i], 0.25) for i in range(n_col)])\n",
    "        range_max = np.array([self.tukey_fences(self.glm_mat[:, i], 0.75) for i in range(n_col)])\n",
    "        interc = (range_max[0] - range_min[0]) * np.random.uniform(low=0, high=1, size=self.nknots) + range_min[0]\n",
    "        variab = (range_max[1] - range_min[1]) * np.random.uniform(low=0, high=1, size=self.nknots) + range_min[1]\n",
    "\n",
    "        if self.ran_int and self.ran_var:\n",
    "            knots = np.column_stack((interc, variab))\n",
    "        elif self.ran_int and not self.ran_var:\n",
    "            knots = interc\n",
    "        elif not self.ran_int and self.ran_var:\n",
    "            knots = variab\n",
    "        else:\n",
    "            print(\"You should set at least one among ran_int and ran_var equal to True\")\n",
    "            knots = None\n",
    "        return range_min, range_max, knots\n",
    "\n",
    "    def set_parameters(self):\n",
    "        if self.sim:\n",
    "            if self.data is None and self.t is None and self.fix is None and self.lengths is None \\\n",
    "                    and self.eta is None and self.y is None:\n",
    "                self.data, self.t, self.fix, self.lengths = self.generate_curves()\n",
    "                self.eta, self.y = self.compute_eta_and_y()\n",
    "                while self.check_balance():\n",
    "                    self.data, self.t, self.fix, self.lengths = self.generate_curves()\n",
    "                    self.eta, self.y = self.compute_eta_and_y()\n",
    "\n",
    "        if self.glm_mat is None:\n",
    "            self.glm_mat = self.compute_glm_mat()\n",
    "\n",
    "        if self.par is None:\n",
    "            self.par = self.compute_par()\n",
    "\n",
    "        if self.range_min is None and self.range_max is None and self.knots is None:\n",
    "            self.range_min, self.range_max, self.knots = self.compute_ranges_knots()\n",
    "\n",
    "    def plots(self):\n",
    "        for i in range(self.N):\n",
    "            ax = sns.histplot(self.y[i])\n",
    "            sns.despine(offset=1, left=False, bottom=False)\n",
    "            ax.axes.vlines(x=np.mean(self.y[i]), color='red', linewidth=0.8, alpha=.8, ymin=-0.6, ymax=70, ls='--')\n",
    "            plt.show()\n",
    "        return\n",
    "\n",
    "    @abstractmethod\n",
    "    def L_ij(self, d, a, b):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def l_ij(self, a, b):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerationBernoulli(DataGeneration):\n",
    "    def __init__(self, ran_var, ran_int, n_fix, sim, fix=None, lengths=None, y=None, N=None, t=None):\n",
    "        super().__init__(ran_var, ran_int, n_fix, sim, fix, lengths, y, N, t)\n",
    "        if self.sim:\n",
    "            r = np.random.RandomState(1234)\n",
    "            self.fix_var_values = np.ceil(r.uniform(-10, 10, n_fix))\n",
    "            self.ran_var_values = np.array([10, 5, 0])\n",
    "            if self.ran_int:\n",
    "                self.int_values = np.array([5, 2, -10])\n",
    "            else:\n",
    "                r2 = np.random.RandomState(1235)\n",
    "                self.int_values = np.repeat(np.ceil(r2.uniform(-10, 10, 1)), self.groups_teor)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def pi(x):\n",
    "        return np.exp(x) / (1 + np.exp(x))\n",
    "    \n",
    "    def compute_eta_and_y(self):\n",
    "        eta = [self.pi(self.data[i]) for i in range(self.N)]\n",
    "        y = eta\n",
    "\n",
    "        for i in range(self.N):\n",
    "            for j in range(self.lengths[i]):\n",
    "                y[i][j] = 0 if (np.random.uniform(0, 1, 1)[0] > eta[i][j]) else 1\n",
    "\n",
    "        return eta, y\n",
    "    \n",
    "    def check_balance(self):\n",
    "        table = [np.array(np.unique(x, return_counts=True)).T for x in self.y]\n",
    "\n",
    "        for i in range(len(table)):\n",
    "            if table[i].size == 2:\n",
    "                return True\n",
    "\n",
    "            perc = table[i][0, 1] / (table[i][0, 1] + table[i][1, 1])\n",
    "            if (perc > 0.95) or (perc < 0.05):\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def compute_glm_mat(self):\n",
    "        reg = LogisticRegression(random_state=0)\n",
    "        if self.ran_var:\n",
    "            glm_mat = np.array([\n",
    "                np.concatenate((\n",
    "                    reg.fit(pd.concat([pd.DataFrame(self.t[i]), pd.DataFrame([v[i] for k, v in self.fix.items()]).T],\n",
    "                                      axis=1), self.y[i]).intercept_,\n",
    "                    reg.fit(pd.concat([pd.DataFrame(self.t[i]), pd.DataFrame([v[i] for k, v in self.fix.items()]).T],\n",
    "                                      axis=1), self.y[i]).coef_[0]))\n",
    "                for i in range(self.N)])\n",
    "        else:\n",
    "            glm_mat = np.array([\n",
    "                np.concatenate((\n",
    "                    reg.fit(pd.DataFrame([v[i] for k, v in self.fix.items()]).T, self.y[i]).intercept_,\n",
    "                    reg.fit(pd.DataFrame([v[i] for k, v in self.fix.items()]).T, self.y[i]).coef_[0]))\n",
    "                for i in range(self.N)])\n",
    "        return glm_mat\n",
    "\n",
    "    def L_ij(self, d, a, b):\n",
    "        if a == 0:\n",
    "            #return d * (1 / (1 + np.exp(b)))\n",
    "            return d - np.log(1 + np.exp(b))\n",
    "        else:\n",
    "            #return d * (1 / (1 + 1 / np.exp(b)))\n",
    "            return d + b - np.log(1 + np.exp(b))\n",
    "\n",
    "    def l_ij(self, a, b):\n",
    "        return a * b - np.log(1 + np.exp(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerationPoisson(DataGeneration):\n",
    "    def __init__(self, ran_var, ran_int, n_fix, sim, fix=None, lengths=None, y=None, N=None, t=None):\n",
    "        super().__init__(ran_var, ran_int, n_fix, sim, fix, lengths, y, N, t)\n",
    "\n",
    "        if self.sim:\n",
    "            r = np.random.RandomState(1234)\n",
    "            self.fix_var_values = np.round(r.uniform(0, 1.5, n_fix), 1)\n",
    "            self.ran_var_values = np.array([0.5, 0.2, 0.1])\n",
    "            if self.ran_int:\n",
    "                self.int_values = np.array([2.5, 1, -1])  \n",
    "                # for the moment no implementation of the other parts\n",
    "\n",
    "    def compute_eta_and_y(self):\n",
    "        eta = [np.exp(self.data[i]) for i in range(self.N)]\n",
    "        y = eta\n",
    "\n",
    "        for i in range(self.N):\n",
    "            for j in range(self.lengths[i]):\n",
    "                h = eta[i][j].astype(np.float64)\n",
    "                y[i][j] = np.random.poisson(lam=h)\n",
    "\n",
    "        return eta, y\n",
    "    \n",
    "    def check_balance(self):\n",
    "        for i in self.y:\n",
    "            for j in i:\n",
    "                if j >= 100:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def compute_glm_mat(self):\n",
    "        reg = PoissonRegressor()\n",
    "        glm_mat = []\n",
    "        for i in range(self.N):\n",
    "            if self.ran_var:\n",
    "                x = pd.concat([pd.DataFrame(self.t[i]), pd.DataFrame([v[i] for k, v in self.fix.items()]).T], axis=1)\n",
    "            else:\n",
    "                x = pd.DataFrame([v[i] for k, v in self.fix.items()]).T\n",
    "\n",
    "            a = reg.fit(x, self.y[i])\n",
    "            glm_mat = np.append(glm_mat, np.append([a.intercept_], a.coef_))\n",
    "\n",
    "        glm_mat.shape = (self.N, np.int64(glm_mat.size / self.N))\n",
    "        return glm_mat\n",
    "\n",
    "    def L_ij(self, d, a, b):\n",
    "        if a == 0:\n",
    "            #return d * np.exp(- np.exp(b))\n",
    "            return d - np.exp(b) \n",
    "        else:\n",
    "            #return d * np.exp(a * b - np.exp(b)) #* 1 / (np.nan_to_num(factorial(a)))\n",
    "            return d + a * b - np.exp(b) - np.log(np.nan_to_num(factorial(a)))\n",
    "\n",
    "    def l_ij(self, a, b):\n",
    "        return a * b - np.exp(b) - np.log(np.nan_to_num(factorial(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DGB = DataGenerationBernoulli(ran_var = False, ran_int = True, n_fix = 1, sim = True, fix=None, lengths=None, y=None, N=None, t=None)\n",
    "DGP = DataGenerationPoisson(ran_var = False, ran_int = True, n_fix = 1, sim = True, fix=None, lengths=None, y=None, N=None, t=None)\n",
    " \n",
    " \n",
    "DGP.set_parameters() # per “riempire” la classe\n",
    "DGP.N # questi sono i numeri dei gruppi (10 per il caso simulato)\n",
    "DGP.int_values # queste sono le random intercepts\n",
    "DGP.lengths # queste sono le numerosità in ogni gruppo\n",
    "DGP.y # risposta\n",
    "DGP.par # coefficienti fissi (in questo caso è uno perché n_fix = 1, ma si può modificare n_fix e questo varia)\n",
    "DGP.fix # covariate fisse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
